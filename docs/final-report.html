<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  pre {
    display: inline;
  }
  img {
    width: 700px;
  }
  .slideshow {
    max-width: 700px;
    position: relative;
    margin: auto;
  }
  /* Next & previous buttons */
  .prev, .next {
    cursor: pointer;
    position: absolute;
    top: 50%;
    width: auto;
    margin-top: -22px;
    padding: 16px;
    color: white;
    font-weight: bold;
    font-size: 36px;
    transition: 0.6s ease;
    border-radius: 0 3px 3px 0;
  }

  /* Position the "next button" to the right */
  .next {
    right: 0;
    border-radius: 3px 0 0 3px;
  }

  /* On hover, add a black background color with a little bit see-through */
  .prev:hover, .next:hover {
    background-color: white;
    color: black;
  }
</style>
<title>CS 184 Final Project</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<script>
  var images = ['cube', 'quadball', 'bean', 'beetle', 'maxplanck', 'teapot'];

  var currentSlides = {};
  for (var i = 0; i < images.length; i++) {
    currentSlides[images[i]] = 0;
  }

  var slideClasses = {};
  slideClasses['cube'] = ['images/cube_pc.png',
                          'images/cube_bpa.png',
                          'images/cube_real.png',];
  slideClasses['quadball'] = ['images/quadball_pc.png',
                              'images/quadball_bpa.png',
                              'images/quadball_real.png',];
  slideClasses['bean'] = ['images/bean_pc.png',
                          'images/bean_bpa.png',
                          'images/bean_real.png',];
  slideClasses['beetle'] = ['images/beetle_pc.png',
                            'images/beetle_bpa.png',
                            'images/beetle_real.png',];
  slideClasses['maxplanck'] = ['images/maxplanck_pc.png',
                               'images/maxplanck_bpa1.png',
                               'images/maxplanck_bpa2.png',
                               'images/maxplanck_real1.png',
                               'images/maxplanck_real2.png',];
  slideClasses['teapot'] = ['images/teapot_pc2.png',
                            'images/teapot_bpa1.png',
                            'images/teapot_bpa2.png',
                            'images/teapot_real.png',];

  var slideCaptions = {};
  slideCaptions['cube'] = ['Point Cloud (there are only 8 points, so they are difficult to see)',
                           'BPA solution with <pre>r = 2.0</pre>',
                           'Actual mesh',];
  slideCaptions['quadball'] = ['Point Cloud',
                               'BPA solution with <pre>r = 0.5</pre>',
                               'Actual mesh',];
  slideCaptions['bean'] = ['Point Cloud',
                           'BPA solution with <pre>r = 0.2</pre>',
                           'Actual mesh',];
  slideCaptions['beetle'] = ['Point Cloud',
                             'BPA solution with <pre>r = 0.04</pre>',
                             'Actual mesh',];
  slideCaptions['maxplanck'] = ['Point Cloud',
                                'BPA solution with <pre>r = 0.025</pre>',
                                'BPA solution with <pre>r = 0.025</pre> (zoomed in)',
                                'Actual mesh',
                                'Actual mesh (zoomed in)',];
  slideCaptions['teapot'] = ['Point Cloud',
                             'BPA solution with <pre>r = 0.1</pre>',
                             'BPA solution with <pre>r = 0.05</pre>',
                             'Actual mesh',];
  
  document.addEventListener("DOMContentLoaded", function(event) {
    for (var i = 0; i < images.length; i++) {
      showSlide(0, images[i]);
    }
  });

  function incrementSlides(n, imgId) {
    var newSlide = (currentSlides[imgId] + n) % slideClasses[imgId].length;
    currentSlides[imgId] = newSlide;
    showSlide(newSlide, imgId);
  }

  function showSlide(n, imgId) {
    var slides = document.getElementById(imgId);
    slides.src = slideClasses[imgId][n];
    var caption = document.getElementById(imgId + '_caption');
    caption.innerHTML = slideCaptions[imgId][n];
  }
</script>

  
<body>

  <h1 align="middle">CS 184 Final Project Report: Triangle Mesh Generation from Point Clouds</h1>
  <h2 align="middle">Allan Levy (26721352), Joseph Reid (26845757), Nicholas Kriss (26141698)</h2>


  <br><br>


  <h2 align="middle">Abstract</h2>
  <p>
    With the surging popularity of VR, video games, and animated movies, the demand for realistic renderings of objects has grown incredibly. However, the limiting factor in this growth is the difficulty in being able to artificially construct a realistic object from nothing. One way to bypass this is by using 3D scanners. 3D scanners are able to model an object in 3D space on a computer by gathering thousands of samples of the locations of points on the surface of an object. These points can then be displayed on a screen as a point cloud. However, in order to be able to interact with this object, we need to construct a mesh, a structure that combines these points with edges and faces that connect them. It is not trivial, though, to determine which vertices to connect, as there are often many neighboring candidate vertices to choose from. In this project, we first extend the MeshEdit executable to visualize point clouds. We then implement the Ball Pivot Algorithm (BPA) to build and then display a new mesh structure from these point clouds.
  </p>

  <br>



  <h2 align="middle">The Ball Pivot Algorithm</h2>

  <p><pre></pre>
    To build our mesh, we implemented the Ball Pivot Algorithm to iteratively find triangles. The general idea is to simulate a ball with radius <pre>r</pre>, which is wide enough that the ball can "sit" between 3 points in the cloud without falling through. We create a triangle using those 3 points and "rotate" the ball around one of that triangle's edges. If the ball is stopped in its rotation by another vertex, then edges are added to the mesh to create a triangle between the rotated edge and that point. This is repeated until we find no more triangles to add. To begin, we divide up the mesh into a 3D grid of voxels in order to more efficiently find neighboring vertices to a given point. We then determine a "seed triangle", or an arbitrary set of 3 vertices that satisfy the necessary conditions to allow the simulated ball to sit upon them. We create edges between those 3 vertices and add the resulting triangle to our mesh. These 3 edges are placed into a queue called the "Front." In the Front, each edge stores its bounding vertices, the position of the ball when the edge was created, and whether the edge is a boundary (i.e. the rotated ball found nothing, and therefore there are no further triangles to make from this edge). We iteratively pop edges off of the Front and rotate the ball around them. If the ball finds a point, edges are created from our active edge to the new point, the new edges are added to the Front, and the new triangle is added to the mesh. The active edge is removed from the Front because it is no longer on the outside edge of our mesh and is therefore no longer useful for finding new triangles in a manifold object. We continue rotating the ball around all edges in the Front until the Front is empty. At this point, we search for a new seed triangle, in case there are disjoint pieces of the point cloud which must be processed. Once there are no more seed triangles to be found, the algorithm is complete.
  </p>

  <br>

  <div align="middle">
    <img src="images/bpa_3.png"/>
    <figcaption align="middle">BPA pseudocode</figcaption>
  </div>

  <br>



  <h2 align="middle">PLY Files and Point Cloud Display</h2>
  <p><pre></pre>
    Before we began implmenting BPA, we wanted to be able to visualize the point clouds. This would allow us to visualize the data and to compare our completed mesh with after it was constructed. Therefore, we first wrote a program to parse the <pre>.PLY</pre> files given from the <a href="http://graphics.stanford.edu/data/3Dscanrep/">Stanfurd 3D Scanning Repository</a> and display the point clouds. Below are a few screenshots of the point cloud of the Stanfurd bunny.
  </p>

  <div align="middle">
    <img src="images/bun000_point_cloud_1.png"/>
    <figcaption align="middle">Point cloud of the front of the Stanfurd Bunny</figcaption>

    <br>

    <img src="images/bun000_point_cloud_2.png"/>
    <figcaption align="middle">Point cloud of the front of the Stanfurd Bunny</figcaption>

    <br>

    <img src="images/bun000_point_cloud_3.png"/>
    <figcaption align="middle">Point cloud of the front of the Stanfurd Bunny</figcaption>
  </div>

  <br>

  <p>
    However, shortly after finishing this we ran into our first problem. While reading through the <pre>.PLY</pre> files, we realized that they did not contain the point normals. These normal vectors are necessary in BPA to be able to determine which way "out" and "in" are so that it knows which way to rotate the ball to create an orientable manifold. This was a big setback because we had already invested much time into creating the <pre>.PLY</pre> to Display pipeline. After realizing that BPA would not work well without these point normals, we came up with two options to remedy this:
    <ol>
      <li>Average the surrounding face normals of a point supplied in the completed meshes that came with the <pre>.PLY</pre> files</li>
      <li>Average the surrounding face normals of each point in the <pre>.DAE</pre> files of the completed meshes from Project 2 in order to estimate the point normals</li>
    </ol>
    We chose the second.
  </p>

  <br>



  <h2 align="middle">Implementation</h2>

  <p><pre></pre>
    After adding a command line flag <pre>-p</pre> to be able to visualize a <pre>.DAE</pre> point cloud by only displaying the points, we began implementing BPA, which includes five new functions. The actual algorithm replaces the <pre>MeshResampler::upsample</pre> function in <pre>student_code.cpp</pre> in Project 2, so that there is an existing framework to run the program from the meshedit GUI. It begins by loading a <pre>.DAE</pre> file like normal. When the "p" key is pressed, BPA begins to run. First, for each point it averages the surround face normals and adds that normal into the <pre>Vertex</pre> object's <pre>normal</pre> attribute. We then clear all of the edges and faces, leaving us with just the points and their normals. We then begin the actual algorithm, which includes several of the helper functions shown above in the pseudocode. These include:
    <ul>
      <li><pre>seed_triangle(...)</pre>: returns a new seed triangle when the front is empty; also creates the sphere touching all three points, ensuring that it does not contain any other points and that the vertex normals point in the same direction as the face normal</li>
      <li><pre>join(...)</pre>: joins the edge being pivoted around with a vertex to create a new face</li>
      <li><pre>glue(...)</pre>: "glues" together two halfedges to form one edge; this occurs when one halfedge is already in the Front, and removes the edge from the Front</li>
      <li><pre>get_center(...)</pre>: finds the center of a sphere of a given radius that touches three given points in space</li>
    </ul>
  </p>

  <div align="middle">
    <img src="images/bpa_1.png"/>
    <!-- <figcaption align="middle">BPA pseudocode</figcaption> -->
  </div>

  <br>



  <h2 align="middle">Problems and Solutions</h2>

  <p><pre></pre>
    As specified earlier, the first major problem we encountered was in finding valid inputs to the algorithm. BPA requires that we have access to the normal vectors for every vertex in the point cloud, so that we can be sure that the normal of each face is consistent with the normals of its vertices and that our final mesh will be orientable and manifold. However, the point clouds and meshes given by the Stanfurd Repository do not have any face or vertex normals, so we decided to just use the <pre>.DAE</pre> files given to us for Project 2 and calculated the vertex normals using the <pre>Vertex::normal(...)</pre> function written for that assignment and saving them to a new <pre>Vector3D</pre> norm added to the <pre>VertexIter</pre> class. Since we take in a complete <pre>HalfedgeMesh</pre> but only want a point cloud, we have to delete the mesh's edges, halfedges, faces, and boundaries at the start of the algorithm. A related issue arose at the end of the project, since the default <pre>Face::normal</pre> function expects that the vertices are entered and subsequently accessed in a particular order, which will probably change when we rebuild the mesh. To fix this, we added a check so that <pre>Face::normal</pre> returns the unit normal vector sum of the cross products if it points in the same direction as the average of the vertex normals, and otherwise returns the unit normal vector in the opposite direction.
  </p>

  <p><pre></pre>
    We also experienced many bugs in our early code, mostly related to the voxel grid and rotating the ball. To find the voxel containing a given vertex, we used a hash function that finds the <pre>x</pre>, <pre>y</pre>, and <pre>z</pre> positions of the voxel and calculates the position of the voxel in the vector of voxels. We initially copied the hash function code we wrote for Project 4, but this caused the program to crash on certain radius inputs. We eventually realized that the problem was that we were hashing with respect to the point <pre>(0, 0, 0)</pre>, which caused some negative numbers to hash to a negative index. To fix this, we added a <pre>minDimensions</pre> input to the hash function, which we subtract from the absolute position of the point to get its position relative to the most negative corner of the bounding box.
  </p>
    
  <p><pre></pre>
    The other major issue was finding the first center on the trajectory around a given point. It was easy to use dot products to find the smaller angle between the lines connecting the original center with the midpoint and the new center with the midpoint, which would give us the angle along the trajectory. However, we needed to account for the direction of the rotation, so that for rotations "below" the surface of the triangle the actual angle would be <pre>2*PI</pre> minus the calculated angle. By drawing it out, we initially thought we could solve this by checking that the cross product of the original radius, from the midpoint to the first center, with the new radius, from the midpoint to the new center, was in the same direction as the cross product between the old radius and the line from the midpoint to the circumcenter of the circle around the three vertices of the face. If these cross products were in the same direction, we could say that we were at least <pre>PI</pre> along the trajectory. However, this only accounted for the case where the circumcenter was on the same side of the rotation edge as the opposite vertex, and in fact the opposite relationship holds if the circumcenter is on the opposite side of the rotation line from the opposite vertex. Finally, we needed to add a small delta so that we only recalculate the angle of rotation if that angle is above a certain value. Otherwise, we might think that extremely non-zero rotations foward are actually extremely small rotations backwards and thus large rotations along our trajectory.
  </p>

  <br>



  <h2 align="middle">Results</h2>

  <p><pre></pre>
    Below are renders of the result of running BPA on several <pre>.DAE</pre> files given in Project 2. You can use the arrow buttons on the sides of the images to switch between views of the point cloud, BPA result, and mesh provided in Project 2 (used as a comparison).
  </p>

  <br>

  <h3 align="middle"><pre>cube.dae</pre></h3>
  <div class="slideshow">
    <img id="cube" style="width:100%">
    <figcaption align="middle" id="cube_caption"></figcaption>
    <div class="arrows" style="width:100%">
      <div class="prev" onclick="incrementSlides(-1, 'cube')">&#10094;</div>
      <div class="next" onclick="incrementSlides(1, 'cube')">&#10095;</div>
    </div>
  </div>

  <br>

  <h3 align="middle"><pre>quadball.dae</pre></h3>
  <div class="slideshow">
    <img id="quadball" style="width:100%">
    <figcaption align="middle" id="quadball_caption"></figcaption>
    <div class="arrows" style="width:100%">
      <div class="prev" onclick="incrementSlides(-1, 'quadball')">&#10094;</div>
      <div class="next" onclick="incrementSlides(1, 'quadball')">&#10095;</div>
    </div>
  </div>

  <br>

  <h3 align="middle"><pre>bean.dae</pre></h3>
  <div class="slideshow">
    <img id="bean" style="width:100%">
    <figcaption align="middle" id="bean_caption"></figcaption>
    <div class="arrows" style="width:100%">
      <div class="prev" onclick="incrementSlides(-1, 'bean')">&#10094;</div>
      <div class="next" onclick="incrementSlides(1, 'bean')">&#10095;</div>
    </div>
  </div>

  <br>

  <h3 align="middle"><pre>beetle.dae</pre></h3>
  <div class="slideshow">
    <img id="beetle" style="width:100%">
    <figcaption align="middle" id="beetle_caption"></figcaption>
    <div class="arrows" style="width:100%">
      <div class="prev" onclick="incrementSlides(-1, 'beetle')">&#10094;</div>
      <div class="next" onclick="incrementSlides(1, 'beetle')">&#10095;</div>
    </div>
  </div>

  <br>

  <h3 align="middle"><pre>maxplanck.dae</pre></h3>
  <div class="slideshow">
    <img id="maxplanck" style="width:100%">
    <figcaption align="middle" id="maxplanck_caption"></figcaption>
    <div class="arrows" style="width:100%">
      <div class="prev" onclick="incrementSlides(-1, 'maxplanck')">&#10094;</div>
      <div class="next" onclick="incrementSlides(1, 'maxplanck')">&#10095;</div>
    </div>
  </div>

  <br>



  <h2 align="middle">Challenges with BPA</h2>

  <p>
    As you have seen in the results above, the algorithm isn't perfect. A "good" radius for the ball size depends entirely on the location of the points within the point cloud and the concavity of the manifold.
  </p>

  <div align="middle">
    <img src="images/bpa_2.png"/>
  </div>

  <p><pre></pre>
    In image (b) above, too small of a radius results in the ball falling through the space between two neighboring vertices, resulting in a missed edge or face. In image (c), too big of a radius results in creating incorrect edges and faces in concave areas. Below, <pre>teapot.dae</pre> shows this tradeoff.
  </p>

  <h3 align="middle"><pre>teapot.dae</pre></h3>
  <div class="slideshow">
    <img id="teapot" style="width:100%">
    <figcaption align="middle" id="teapot_caption"></figcaption>
    <div class="arrows" style="width:100%">
      <div class="prev" onclick="incrementSlides(-1, 'teapot')">&#10094;</div>
      <div class="next" onclick="incrementSlides(1, 'teapot')">&#10095;</div>
    </div>
  </div>

  <p><pre></pre>
    The teapot works much worse than the other objects above because the points are very unevenly spaced apart. On the sides of the teapot, the points are spread far apart. However, on the handle, spout, and near the edges, the points are much more close together. Therefore, this one-size-fits-all approach of BPA with one ball radius fails to create an accurate mesh.
  </p>

  <p>
    There are a few ways to solve this problem, though. One way to fix this is (1) when 3D-scanning the object, sample more evenly from the object. This is demonstrated in the Max Planck rendering, which despite having many more points than teapot, has a much more accurate mesh because its points were sampled more closely together. Another way to solve this issue would be to (2) run BPA multiple times with different size radii. If we had more time for this project, we would have done just that. The challenge with this, though, is that vertices are marked as "used" and not returned to again. Therefore, if we were to discover an area where a certain radius was unsuccessful in creating a face, we would have to mark those vertices as "unused" first before running BPA again with a different radius.
  </p>

  <br>

  <h2 align="middle">Video</h2>
  <div align="middle">
    <video width="700px" controls>
      <source src="videos/final.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>


  <h2 align="middle">References</h2>
  
  <ul>
    <li><a href="https://vgc.poly.edu/~csilva/papers/tvcg99.pdf">The Ball-Pivoting Algorithm for Surface Reconstruction</a></li>
    <li><a href="http://graphics.stanford.edu/data/3Dscanrep/">Stanfurd 3D Scanning Repository</a></li>
  </ul>


  <h2 align="middle">Contributions</h2>
  
  <ul><pre></pre>
    <li>Allan: project planning, initial algorithm pseudocode, various debugging, milestone video, final presentation slides</li>
    <li>Joseph: <pre>.PLY</pre> to visualizing point cloud pipeline, additional command line flags, milestone video, final video, write-ups, presentation slides, various debugging</li>
    <li>Nicholas: </li>
  </ul>


</body>
</html>
